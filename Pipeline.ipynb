{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8059980",
   "metadata": {},
   "outputs": [],
   "source": [
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import time\n",
    "        import seaborn as sns\n",
    "        import statsmodels.api as sm\n",
    "        import matplotlib.pyplot as plt\n",
    "        from pymystem3 import Mystem\n",
    "        import datasist as ds\n",
    "        import nltk\n",
    "        import re\n",
    "        from scipy import stats\n",
    "        import shap\n",
    "        from sklearn.metrics import plot_precision_recall_curve\n",
    "        from sklearn.metrics import plot_confusion_matrix\n",
    "        from sklearn import metrics\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        from sklearn.preprocessing import OrdinalEncoder\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        from sklearn.preprocessing import Binarizer\n",
    "        import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a38cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bb7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipe():\n",
    "    \"\"\"\n",
    "    info\n",
    "    \n",
    "    getColWithNaN - Get all columns from dataframe with NaN values.\n",
    "    getCatCol - Get categorical columns of dataframe\n",
    "    getNumCol - Get numeric columns of dataframe\n",
    "    benchmark - returns duration of execution and function result\n",
    "    getInfo   - short info with columns (Column name, datatype, null values count, unique values count, useless property)\n",
    "    getQuantile - get 1.5 quantile diap\n",
    "    \n",
    "    preprocessing\n",
    "    \n",
    "    downcastNumCol - downcast all numeric columns\n",
    "    fillnaByGroup - fill NA values with value by group according kind param\n",
    "    fillnaCat - fill missing values by word 'missing' and replace rare values with 'rare'\n",
    "    drop_useless - drop useless columns like index, id etc.\n",
    "    convert_dtype - automatically type-cast features that are not represented in their right types  \n",
    "    create_balanced_data - creates a balanced data set from an imbalanced one. This function is strictly used in a classification task\n",
    "    scaler - transfom numeric data by params 'no': Normalizer(),\n",
    "                                             'ss': StandardScaler(),\n",
    "                                             'mm': MinMaxScaler(),\n",
    "                                             'bc': Boxcox,\n",
    "                                             'ln': Boxcox with lambda =0\n",
    "    graph\n",
    "    \n",
    "    boxplot - draw sns boxplot\n",
    "    hist    - draw sns hist\n",
    "    kdeplot    - draw sns kdeplot\n",
    "    corrmatrix - draw corrmatrix for all columns\n",
    "    pie     - draw pie plot\n",
    "    jointplot - draw jointplot\n",
    "    qqplot   - draw qqplot\n",
    "    numcolgraph - draw row of plots (kdeplot, boxplot, qqplot, statistic table (modified describe))\n",
    "    \n",
    "    text\n",
    "    \n",
    "    getLemmas - get lemmas by getLemmas by nltk.tokenize.word_tokenize, SnowballStemmer or Mystem (russian only)\n",
    "    clear_text_cyr - clear text, left only cyrillic letters\n",
    "    clear_text_lat - clear text, left only latin letters\n",
    "    clear_text_cyr_lat - clear text, left only cyrillic and latin letters\n",
    "    \n",
    "    models\n",
    "    \n",
    "    _get_classification_model_list - create list of popular classification models with basic params\n",
    "    _get_regression_model_list     - create list of popular regression models with basic params\n",
    "    compare_model - This function takes as argument multiple machine learning models and returns a plot of a comparative metric. \n",
    "                    This can be used to pick a base model and also to compare models side by side. \n",
    "                    The compare model returns a tuple of the trained models and their score \n",
    "    plot_feature_importance - plot feature importance\n",
    "    \n",
    "    analyses\n",
    "    \n",
    "    confusion_matrix - draw confusion matrix\n",
    "    precision_recall_curve - draw confusion matrix precision recall curve\n",
    "    plotROC - draw AUC ROC plot\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "       \n",
    "        pass\n",
    "    class info:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "        def _checkforUseless(series):\n",
    "            n_distinct_values = series.nunique()\n",
    "            if n_distinct_values == len(series):\n",
    "                # could be an index\n",
    "                if series.iloc[0] == 0:\n",
    "                    if (series == np.arange(len(series))).all():\n",
    "                        # definitely an index\n",
    "                        return True\n",
    "                elif series.iloc[0] == 1:\n",
    "                    if (series == np.arange(1, len(series) + 1)).all():\n",
    "                        # definitely an index\n",
    "                        return True\n",
    "            if n_distinct_values==1:\n",
    "                return True\n",
    "            return False\n",
    "        def getQuantile(series):\n",
    "            q1=series.quantile(0.25)\n",
    "            q3=series.quantile(0.75)\n",
    "            mr = q3 - q1\n",
    "            low =q1-mr*1.5 if q1-mr*1.5>series.min() else series.min()\n",
    "            high = q3+mr*1.5 if q1+mr*1.5<series.max() else series.max()\n",
    "            print('1.5 interquantile distance: {:.0f}-{:.0f}'.format(low, high))\n",
    "            return low, high\n",
    "       \n",
    "        def benchmark(func,*args):\n",
    "            \n",
    "            t = time.perf_counter()\n",
    "            res = func(*args)\n",
    "            return time.perf_counter() - t, res\n",
    "        def getColWithNaN(df):\n",
    "            return df.columns[df.isnull().sum()>0]\n",
    "        def getCatCol(df):\n",
    "            return df.columns[(df.dtypes=='object')|(df.dtypes=='category')]\n",
    "        def getNumCol(df):\n",
    "            return df.columns[df.dtypes!='object']\n",
    "        def getInfo(df):\n",
    "            info=pd.concat([pd.DataFrame(df.columns).set_index(0),\\\n",
    "                            pd.DataFrame(df.dtypes),\\\n",
    "                            df.count(),\\\n",
    "                            pd.DataFrame(df.isnull().sum()),\\\n",
    "                                (df.isnull().sum()/df.shape[0]).map(lambda x: '{:.2%}'.format(x)),\\\n",
    "                            pd.DataFrame(map(lambda x: df[x].nunique(),df.columns), index=df.columns),\\\n",
    "                            pd.DataFrame(map(lambda x: pipe.info._checkforUseless(df[x]),df.columns), index=df.columns)],\\\n",
    "                            axis=1, join ='inner')\n",
    "            info.columns=['DataType','Values','Null', 'Missing Rate', 'Unique','Useless']  \n",
    "            return info\n",
    "    class preprocessing():\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        def downcastNumCol(df, cols):\n",
    "            for col in cols:\n",
    "                if 'int' in str(df[col].dtype):\n",
    "                    df[col]=pd.to_numeric(df[col], downcast=\"integer\")\n",
    "                elif 'float' in str(df[col].dtype): \n",
    "                    df[col]=pd.to_numeric(df[col], downcast=\"float\")\n",
    "            return df            \n",
    "        def fillnaByGroup(df,col_to_fill, group, kind='median'):\n",
    "            if col_to_fill not in pipe.info.getNumCol(df):\n",
    "                print('col_to_fill must be numeric')\n",
    "            if kind not in ['median','mean']:\n",
    "                print(\"Only kind in ('median','mean') available\")\n",
    "            df.loc[df[col_to_fill].isna(),\"distance\"] = df.groupby(group)[col_to_fill].transform(kind)\n",
    "            return df\n",
    "        def fillnaCat(df, thr = 0.005):\n",
    "            for col in pipe.info.getCatCol(df):\n",
    "                df[col]=df[col].astype('object')\n",
    "                df.loc[df[col].isnull(), col] = 'missing'\n",
    "            for col in pipe.info.getCatCol(df):\n",
    "                d = dict(df[col].value_counts(dropna=False)/len(df))\n",
    "                df[col] = df[col].apply(lambda x: 'rare' if d[x] <= thr else x)\n",
    "            return df\n",
    "        def drop_outliers(df,col, min_max_range=None):\n",
    "             \n",
    "            if min_max_range==None:\n",
    "                low, hight = pipe.info.getQuantile(df[col])\n",
    "            else:\n",
    "                low=min_max_range[0]\n",
    "                hight=min_max_range[1]\n",
    "            df= df[(df[col]<hight)&(df[col]>low)] \n",
    "            return df\n",
    "        def drop_useless(df):\n",
    "            return df.drop(columns=pipe.info.getInfo(df)[pipe.info.getInfo(df)['Useless']==True].index, axis=1)\n",
    "        def convert_dtype(df):\n",
    "            return ds.feature_engineering.convert_dtype(df)\n",
    "        def create_balanced_data(df, target, categories, class_sizes):\n",
    "            return ds.feature_engineering.create_balanced_data (data = df, target = target, categories = categories, class_sizes = class_sizes)\n",
    "        def scale(df,cols=[], kind='ss'):\n",
    "            class ln():\n",
    "                def fit_transform(self,df):\n",
    "                    return df.apply(lambda x: boxcox(x, lmbda=0))    \n",
    "            class bc():  \n",
    "                def fit_transform(self,df):\n",
    "                    return df.apply(lambda x: boxcox(x))    \n",
    "            kinds={'no': Normalizer,\n",
    "                   'ss': StandardScaler,\n",
    "                   'mm': MinMaxScaler,\n",
    "                   'bc': bc,\n",
    "                   'ln': ln\n",
    "                   }      \n",
    "            scaler=kinds.get(kind,'Params error {}- wrong kind'.format(kind))\n",
    "            if isinstance(scaler, str):\n",
    "                print(scaler)\n",
    "                return None\n",
    "            else:         \n",
    "                df[cols]=scaler().fit_transform(df[cols])\n",
    "            return df\n",
    "        def encoder(df, cols=[], kind='oh',**kwargs):    \n",
    "            class oh():\n",
    "                def __init__(self,**kwargs):\n",
    "                    self.drop_first = kwargs.get('drop_first',False)\n",
    "                def fit_transform(self,df):\n",
    "                    dummies = pd.get_dummies(df[cols],drop_first= self.drop_first)\n",
    "                    return dummies\n",
    "            kinds={'oe': OrdinalEncoder,\n",
    "                   'oh': oh,\n",
    "                   'bi': Binarizer,\n",
    "                   'cb': ce.CatBoostEncoder,\n",
    "                   'pn': ce.PolynomialEncoder,\n",
    "                   'he': ce.HashingEncoder\n",
    "                    } \n",
    "            enc=kinds.get(kind,'Params error {}- wrong kind'.format(kind))\n",
    "            if isinstance(enc, str):\n",
    "                print(enc)\n",
    "                return None\n",
    "            else:       \n",
    "                res=enc(**kwargs).fit_transform(df[cols]).astype('int')\n",
    "                if len(cols)==len(res):\n",
    "                    df[cols]= res\n",
    "                else:\n",
    "                    df=df.drop(cols, axis=1)\n",
    "                    df[res.columns]=res\n",
    "                return df\n",
    "    class graph():\n",
    "        \n",
    "        def __init__(self):\n",
    "            pass\n",
    "        def lineplot(df,**kwargs):\n",
    "            plt.figure(figsize=(15,5))\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            ax = sns.lineplot(data=df, **kwargs)\n",
    "            return None\n",
    "        def boxplot(df,**kwargs):\n",
    "            plt.figure(figsize=(15,5))\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            ax = sns.boxplot(data=df, **kwargs)\n",
    "            return None\n",
    "        def kdeplot(df,**kwargs):\n",
    "            plt.figure(figsize=(15,5))\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            ax = sns.kdeplot(data=df, **kwargs)\n",
    "            return None\n",
    "        def jointplot(df,**kwargs):\n",
    "            plt.figure(figsize=(15,5))\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            ax = sns.jointplot(data=df, **kwargs)\n",
    "            return None\n",
    "        def qqplot(series):\n",
    "            fig = sm.qqplot(series,  fit=True, line=\"45\")\n",
    "            plt.show()\n",
    "            return None\n",
    "        def hist(df,x,bins=10):\n",
    "            if x not in sPipe.info.getNumCol(df):\n",
    "                print('X must be numeric')  \n",
    "            plt.figure(figsize=(15,5))    \n",
    "            sns.set_theme(style=\"darkgrid\")\n",
    "            sns.displot(data=df, x=x, bins=bins, kde=True)\n",
    "            return None\n",
    "        def corrmatrix(df):\n",
    "            plt.figure(figsize=(15,5))\n",
    "            sns.set(font_scale=2)\n",
    "            sns.heatmap(df.corr(),cmap='coolwarm',annot = True, annot_kws={\"fontsize\": 'medium'})\n",
    "            return None\n",
    "        def pie(df, category, val):\n",
    "            df.groupby(category)[val].count().plot(kind='pie', autopct='%1.2f%%')\n",
    "            return None\n",
    "        def numcolgraph(series):\n",
    "            PLOTS = 4\n",
    "            PLOT_HEIGHT = 4\n",
    "            fig, axes=plt.subplots(nrows=1,ncols=PLOTS, gridspec_kw={'hspace': 0, 'wspace': 0.4})\n",
    "            fig.set_figheight(PLOT_HEIGHT)\n",
    "            fig.set_figwidth(PLOT_HEIGHT*PLOTS)\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            sns.kdeplot(x=series, ax=axes[0])\n",
    "            sns.boxplot(y=series, ax=axes[1])\n",
    "            ax=sm.qqplot(series,  fit=True, line=\"45\", ax=axes[2])\n",
    "            descr= round(series.describe().append(pd.Series(series.median(), index=['median'])),4)\n",
    "            tbl=axes[3].table(cellText=list(map(lambda x:[x],descr.values)), rowLabels=list(descr.index), colWidths = [0.8], loc = 'upper center')\n",
    "            tbl.scale(1, 2)\n",
    "            tbl.auto_set_font_size(False)\n",
    "            tbl.set_fontsize(16)\n",
    "            axes[3].grid(False)\n",
    "            axes[3].axis('off')\n",
    "    class text():\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "        def getLemmas(series, kind='nltk', language ='english'):\n",
    "            if kind == 'nltk':\n",
    "                nltk.download('punkt')\n",
    "                def tokenize(str):\n",
    "                    return ' '.join(nltk.tokenize.word_tokenize(x,language='english') for x in str.split(' '))\n",
    "                tokens = series.apply(tokenize) \n",
    "            elif kind=='snowball':\n",
    "                stemmer=nltk.stem.SnowballStemmer(language=language)\n",
    "                def get_lemmas(str):\n",
    "                    return ' '.join(stemmer.stem(x) for x in str.split(' '))\n",
    "                tokens = series.apply(get_lemmas) \n",
    "            elif kind=='mystem':\n",
    "                m = Mystem()\n",
    "                def get_lemmas(str):\n",
    "                    lemm_list = m.lemmatize(str)\n",
    "                    return ' '.join(lemm_list)\n",
    "                tokens = series.apply(get_lemmas) \n",
    "            return tokens\n",
    "\n",
    "        def clear_text_cyr(text):\n",
    "            text=re.sub(r'[^а-яА-ЯёЁ]',' ', text)\n",
    "            return ' '.join(text.split())\n",
    "        def clear_text_lat(text):\n",
    "            text=re.sub(r'[^a-zA-Z]',' ', text)\n",
    "            return ' '.join(text.split())\n",
    "        def clear_text_cyr_lat(text):\n",
    "            text=re.sub(r'[^а-яА-ЯёЁa-zA-Z]',' ', text)\n",
    "            return ' '.join(text.split())  \n",
    "\n",
    "    class models():\n",
    "        RANDOM=5888\n",
    "        def __init__():\n",
    "            pass\n",
    "        def _get_classification_model_list(random_state=RANDOM, class_weight=None):\n",
    "            models=[DummyClassifier(strategy='stratified', random_state=random_state),\n",
    "                    LogisticRegression(random_state=random_state, class_weight=class_weight),\n",
    "                    DecisionTreeClassifier(random_state=random_state, class_weight=class_weight),\n",
    "                    LinearDiscriminantAnalysis(),\n",
    "                    KNeighborsClassifier(),\n",
    "                    RandomForestClassifier(random_state=random_state, class_weight=class_weight),\n",
    "                    SVC(random_state=random_state, class_weight=class_weight),\n",
    "                    GradientBoostingClassifier(random_state=random_state)]\n",
    "            return models\n",
    "        def _get_regression_model_list(random_state=RANDOM):\n",
    "            models=[DummyRegressor(strategy='median'),\n",
    "                    LinearRegression(),\n",
    "                    DecisionTreeRegressor(random_state=random_state),\n",
    "                    KNeighborsRegressor(),\n",
    "                    RandomForestRegressor(random_state=random_state),\n",
    "                    SVR(),\n",
    "                    GradientBoostingRegressor(random_state=random_state)\n",
    "                   ]\n",
    "            return models\n",
    "        \n",
    "        def compare_model(model_list, X_train, y_train, scoring,**kwargs):\n",
    "            return ds.model.compare_model(models_list=model_list, x_train=X_train, y_train=y_train, scoring_metric=scoring,**kwargs)\n",
    "        def plot_feature_importance(model, features):\n",
    "            shap_test = shap.Explainer(model,features).shap_values(features)\n",
    "            shap.summary_plot(shap_test, features,  plot_type='violin', max_display=25) \n",
    "            return None\n",
    "    class analysis():\n",
    "        def __init__(self):\n",
    "            pass \n",
    "        def shap(df, model):\n",
    "            shap_test = shap.TreeExplainer(model).shap_values(df)\n",
    "            shap.summary_plot(shap_test, df,\n",
    "                              max_display=25, auto_size_plot=True)\n",
    "            return None\n",
    "        def confusion_matrix(model, X,y):\n",
    "            plot_confusion_matrix(model, X, y) \n",
    "            return None\n",
    "        def precision_recall_curve(model, X,y):\n",
    "            plot_precision_recall_curve(estimator=model, X=X, y=y)\n",
    "            return None\n",
    "        def plotROC(y_test, probs, titl=''):\n",
    "            if titl!='':\n",
    "                titl = ' ('+titl+')' \n",
    "            fpr, tpr, threshold = metrics.roc_curve(y_test, probs)\n",
    "            roc_auc = metrics.auc(fpr, tpr)\n",
    "            plt.title('Receiver Operating Characteristic'+titl)\n",
    "            plt.plot(fpr, tpr, 'b', label = 'AUC = %0.5f' % roc_auc)\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.plot([0, 1], [0, 1],'r--')\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.show()\n",
    "            return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
